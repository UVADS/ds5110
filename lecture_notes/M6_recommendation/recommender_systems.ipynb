{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"uva_seal.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### University of Virginia\n",
    "### DS 5110: Big Data Systems\n",
    "### Recommender Systems\n",
    "### Last updated: January 29, 2023\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sources:\n",
    "\n",
    "- Advanced Analytics with Spark: Chapter 3\n",
    "- [Recommendation engine with Amazon Personalize](https://aws.amazon.com/blogs/architecture/automating-recommendation-engine-training-with-amazon-personalize-and-aws-glue/)\n",
    "- [Non-negative matrix factorization](https://en.wikipedia.org/wiki/Non-negative_matrix_factorization)\n",
    "\n",
    "#### Objectives\n",
    "Introduction to recommender systems\n",
    "\n",
    "#### Concepts\n",
    "\n",
    "- Required data: user data, item data, interaction data\n",
    "- Collaborative filtering\n",
    "- Alternating least squares\n",
    "- Implicit vs. explicit feedback\n",
    "- Exploration vs. exploitation\n",
    "- Finding similar users with cosine similarity\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "\n",
    "Recommender systems are a major application of AI.\n",
    "\n",
    "They have found widespread use across domains to recommend products to users:\n",
    "\n",
    "- Amazon uses them in their e-commerce platform to promote products to users\n",
    "- Netflix recommends streaming content to viewers\n",
    "- Education technology companies build systems to recommend articles/blogs/videos to students and teachers\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three datasets are required for recommender systems:\n",
    "\n",
    "- **User Data**  \n",
    "USER_ID (string), metadata fields\n",
    "\n",
    "- **Item Data**  \n",
    "ITEM_ID (string), metadata fields\n",
    "\n",
    "- **Interaction Data**  \n",
    "USER_ID (string), ITEM_ID (string), TIMESTAMP\n",
    "\n",
    "\n",
    "**Collection Interactions: Implicit vs Explicit Feedback** \n",
    "\n",
    "Recommender systems use interactions between users and products to make relevant recommendations\n",
    "\n",
    "Assumption: historical interactions will be useful in the future\n",
    "\n",
    "**Implicit feedback** can be collected from activity, such as listens, clicks and purchases.  \n",
    "- often automated with *event triggers*\n",
    "- relatively easy to collect\n",
    "\n",
    "**Explicit feedback** is often collected by asking the user to rate a product.  \n",
    "- generally harder to collect\n",
    "- might not match the true feeling of the user  \n",
    "  Example: user says he prefers classical music (explicit), yet all recent listens are hard rock (implicit)\n",
    "\n",
    "In practice, implicit feedback can work better in recommender systems.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborative Filtering**  \n",
    "\n",
    "The concept is simple and appealing: based on user preferences for items, recommend similar items the user is likely to prefer\n",
    "\n",
    "Users assign items a rating (e.g., number of stars)\n",
    "\n",
    "The interaction matrix is generally sparse: low interaction between users and items.\n",
    "\n",
    "Need to compute a similarity metric; for item *i*, return the top *k* most relevant items.\n",
    "Popular method is *cosine similarity*.\n",
    "\n",
    "The cosine of two non-zero vectors **A** and **B** can be derived by using the Euclidean dot product formula:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"cosine_sim.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectors that are closer (smaller angle) have higher cosine and higher similarity.\n",
    "\n",
    "See [here](https://en.wikipedia.org/wiki/Collaborative_filtering) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternating Least Squares (ALS)**  \n",
    "\n",
    "Alternating Least Squares (ALS) is popular for recommendation as it scales well.\n",
    "\n",
    "It uses *latent factors*, which are factors that are unobservable and small in number.  \n",
    "In essence, the factors compress data from a high dimensional space (think PCA) into a much lower dimension.\n",
    "\n",
    "ALS uses a matrix factorization method called *non-negative matrix factorization* (NMF).  \n",
    "Non-negative here because after doing matrix-matrix multiply of the matrix factors, the resulting matrix approximation should not have negative entries (the number of listens on a song is 0+).\n",
    "\n",
    "**Non-Negative Matrix Factorization Example**  \n",
    "Source: Wikipedia  \n",
    "\n",
    "The matrix **V** is represented by the two smaller matrices **W** and **H**, which, when multiplied, approximately reconstruct **V**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"nnf.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrices **W** and **H** need to be estimated, and this is done in an iterative process where estimates on each matrix are produced in an alternating fashion.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amazon Personalize and Example Architecture Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Personalize is a fully-featured recommender system.  \n",
    "\n",
    "Includes different algorithms called *recipes*. See [here](https://docs.aws.amazon.com/personalize/latest/dg/native-recipe-new-item-USER_PERSONALIZATION.html) for more details.\n",
    "\n",
    "Provides parameter that controls *exploration* versus *exploitation*:  \n",
    "\n",
    "**Explore** : items with less interaction data or relevance are recommended more frequently  \n",
    "**Exploit** : recommendations are based on what we know or relevance\n",
    "\n",
    "Personalize tests different item recommendations, learns from user interactions, and boosts recommendations for items driving better engagement.\n",
    "\n",
    "**Example of high-level architecture for a retail customer**  \n",
    "Source: Amazon Web Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"amazon_personalize.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendation in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark MLlib supports recommendation algorithms (both RDD And DF APIs).  \n",
    "\n",
    "Some relevant code for ALS algorithm:\n",
    "```\n",
    "# import packages for RDD API\n",
    "from pyspark.mllib import recommendation\n",
    "from pyspark.mllib.recommendation import *\n",
    "\n",
    "# Train the model\n",
    "model = ALS.trainImplicit(trainData, rank=10, iterations=5, alpha=0.01)\n",
    "\n",
    "```\n",
    "\n",
    "ALS parameters in spark implementation: \n",
    "\n",
    "- `rank`  \n",
    "The number of latent factors in the model, or equivalently, the number of columns $k$ in the user-feature and product-feature matrices. In nontrivial cases, this is also their rank.\n",
    "\n",
    "- `iterations`  \n",
    "The number of iterations that the factorization runs. More iterations take more time but may produce a better factorization.\n",
    "\n",
    "- `lambda`  \n",
    "A standard overfitting parameter. Higher values resist overfitting, but values that are too high hurt the factorizationâ€™s accuracy.\n",
    "\n",
    "- `alpha`  \n",
    "Controls the relative weight of observed versus unobserved user-product interactions in the factorization.\n",
    "\n",
    "There is a programming assignment where you will do end-to-end implementation.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
