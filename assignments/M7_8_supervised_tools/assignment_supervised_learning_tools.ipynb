{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### University of Virginia \n",
    "### DS 5110: Big Data Systems\n",
    "### Assignment: Tools for Supervised Learning\n",
    "### Last Updated: March 16, 2022\n",
    "---  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**  \n",
    "In this assignment, you will code functions to support supervised learning tasks.  The outline is provided below.  The value *None* is used as a placeholder. For random sampling use seed=314 throughout.\n",
    "\n",
    "TOTAL POINTS: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"data preprocessing\") \\\n",
    "    .config(\"spark.executor.memory\", '8g') \\\n",
    "    .config('spark.executor.cores', '4') \\\n",
    "    .config('spark.cores.max', '4') \\\n",
    "    .config(\"spark.driver.memory\",'8g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class = 2 for benign (negative class), 4 for malignant (positive class)\n",
    "target = 'class'\n",
    "positive_label = 4\n",
    "negative_label = 2\n",
    "\n",
    "SEED = 314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "brca = spark.read.csv('breast_cancer_wisconsin.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- clump_thickness: integer (nullable = true)\n",
      " |-- uniformity_cell_size: integer (nullable = true)\n",
      " |-- uniformity_cell_shape: integer (nullable = true)\n",
      " |-- marginal_adhesion: integer (nullable = true)\n",
      " |-- single_epithelial_cell_size: integer (nullable = true)\n",
      " |-- bare_nuclei: string (nullable = true)\n",
      " |-- bland_chromatin: integer (nullable = true)\n",
      " |-- normal_nucleoli: integer (nullable = true)\n",
      " |-- mitoses: integer (nullable = true)\n",
      " |-- class: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the schema\n",
    "brca.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brca.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|class|count|\n",
      "+-----+-----+\n",
      "|    4|  241|\n",
      "|    2|  458|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute distribution of target variable\n",
    "brca.groupBy(target).count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1:  Balancing a DataFrame with Downsampling  \n",
    "i) (**4 PTS**) Write a function to implement downsampling.  Enter code into the cell containing the `downsample` function.  \n",
    "\n",
    "INPUTS  \n",
    "* df               - Spark dataframe  \n",
    "* target           - string, target variable  \n",
    "* positive_label   - integer, value of positive label  \n",
    "* negative_label   - integer, value of negative label  \n",
    "\n",
    "OUTPUT  \n",
    "balanced spark dataframe  \n",
    "\n",
    "Downsampling = sample from larger class to match smaller class size.  \n",
    "\n",
    "**Example:**  \n",
    "\n",
    "INITIAL STATE  \n",
    "Smaller class has 100 records  \n",
    "Larger class size has 400 records\n",
    "\n",
    "ACTION  \n",
    "Sample 100 records from larger class, with replacement  \n",
    "Retain all records from smaller class\n",
    "\n",
    "END STATE    \n",
    "This produces a balanced dataset containing 100 records from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(df, target, positive_label, negative_label):\n",
    "    \"\"\"\n",
    "    df              spark dataframe\n",
    "    target          str, target variable\n",
    "    positive_label  int, value of positive label\n",
    "    negative_label  int, value of negative label\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    ### ENTER CODE HERE\n",
    "    \n",
    "    return df_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) **(1 PT)** Print the target distribution from this balanced dataset, to show the label counts nearly match.\n",
    "\n",
    "#### IMPORTANT NOTE:\n",
    "Sampling won't produce the exact fraction you request. In order to sample efficiently, Spark uses Bernouilli Sampling. \n",
    "Each row is assigned a probability of being included. If you request a 10% sample, each row individually has a 10% chance of being included but this does not guarantee an exact 10% sample   \n",
    "(it should be close, however)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call your downsample function here, and show the count by label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2:  Univariate AUC Measurement  \n",
    "\n",
    "In this exercise, you will measure (in a particular sense) the individual predictive power of the following variables:  \n",
    "* clump_thickness\n",
    "* uniformity_cell_size\n",
    "* uniformity_cell_shape\n",
    "* marginal_adhesion\n",
    "* single_epithelial_cell_size\n",
    "\n",
    "**(5 PTS)** Define a function called `compute_univariate_aucs`  \n",
    "The function needs to do the following:\n",
    "\n",
    "* Split the dataset into training and testing sets (*60% / 40%*, respectively)  \n",
    "* For each variable v:  \n",
    "    * train a logistic regression classifier with intercept, including variable *v* as predictor\n",
    "    * classify each record in the test set  \n",
    "    * measure the area under the ROC curve  \n",
    "* Return a dataframe containing each variable, its model weight (coefficient), and its Univariate AUC, sorted by Univariate AUC in descending order.\n",
    "\n",
    "INPUTS  \n",
    "* df, Spark dataframe \n",
    "* target variable as string\n",
    "* training_fraction  \n",
    "* max_iterations=10  \n",
    "* seed=314  \n",
    "\n",
    "OUTPUTS  \n",
    "dataframe containing three columns: variable name, weight, AUROC  \n",
    "\n",
    "#### IMPORTANT NOTES:   \n",
    "1) If you use the RDD API, LabeledPoint requires that positive label = 1, negative label = 0  \n",
    "2) Do NOT use the downsampling function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the function definition in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the `compute_univariate_aucs` and print the results from the dataframe. Remember not to downsample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
